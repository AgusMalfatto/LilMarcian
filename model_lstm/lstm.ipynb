{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del DataFrame obtenido mediante YahooFinance. \n",
    "Objetivo: Identificar las variables más propensas a influir en el valor de la acción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_prediction(real, prediction):\n",
    "    real_date = real['Date']\n",
    "    real_close = real['Close']\n",
    "\n",
    "    plt.plot(real_date[0:len(prediction)], real_close[0:len(prediction)], color='red', label='Valor real de la acción')\n",
    "    plt.plot(real_date[0:len(prediction)], prediction, color='blue', label='Predicción de la acción')\n",
    "    \n",
    "    # Establecer las etiquetas de las fechas en el eje x\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.ylim(1.1 * np.min(prediction) / 2, 1.1 * np.max(prediction))\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel(\"Valor de la Acción\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = yf.Ticker(\"AAPL\")\n",
    "info = ticker.info\n",
    " \n",
    "data = yf.download(\"GOOGL\", start='2010-07-13', end='2023-10-01')\n",
    "df = pd.DataFrame(data)\n",
    "df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "df.dropna(subset=['SMA_10'], inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date       Close     Volume\n",
      "0    2010-07-26   12.236486   79728192\n",
      "1    2010-07-27   12.328078   97949952\n",
      "2    2010-07-28   12.120871   99740160\n",
      "3    2010-07-29   12.136887  106912980\n",
      "4    2010-07-30   12.133383   85678236\n",
      "...         ...         ...        ...\n",
      "3064 2022-09-26   98.169998   27072700\n",
      "3065 2022-09-27   97.500000   30072800\n",
      "3066 2022-09-28  100.050003   32466300\n",
      "3067 2022-09-29   97.419998   31047200\n",
      "3068 2022-09-30   95.650002   32941500\n",
      "\n",
      "[3069 rows x 3 columns]\n",
      "           Date       Close    Volume\n",
      "3069 2022-10-03   98.639999  27982000\n",
      "3070 2022-10-04  101.639999  28850800\n",
      "3071 2022-10-05  101.430000  22176900\n",
      "3072 2022-10-06  101.419998  22324000\n",
      "3073 2022-10-07   98.680000  27502800\n",
      "...         ...         ...       ...\n",
      "3314 2023-09-25  131.110001  20094600\n",
      "3315 2023-09-26  128.570007  25718700\n",
      "3316 2023-09-27  130.539993  22746500\n",
      "3317 2023-09-28  132.309998  22513100\n",
      "3318 2023-09-29  130.860001  30848100\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agusm\\AppData\\Local\\Temp\\ipykernel_12736\\3462693044.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set.drop(columns=[\"Open\", \"High\", \"Low\", \"Adj Close\", \"SMA_10\"], inplace=True)\n",
      "C:\\Users\\agusm\\AppData\\Local\\Temp\\ipykernel_12736\\3462693044.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validate_set.drop(columns=[\"Open\", \"High\", \"Low\", \"Adj Close\", \"SMA_10\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Extraemos los datos de la media movil hasta el 2022-09-31 para el entrenamiento, y del 2022-10-01 en adelante para la validación\n",
    "train_set = df[df['Date'] <= '2022-09-30']\n",
    "validate_set = df[df['Date'] >= '2022-10-01']\n",
    "# Eliminamos las columnas innecesarias\n",
    "train_set.drop(columns=[\"Open\", \"High\", \"Low\", \"Adj Close\", \"SMA_10\"], inplace=True)\n",
    "validate_set.drop(columns=[\"Open\", \"High\", \"Low\", \"Adj Close\", \"SMA_10\"], inplace=True)\n",
    "\n",
    "print(train_set)\n",
    "print(validate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer la columna \"Date\" como índice\n",
    "train_set.set_index('Date', inplace=True)\n",
    "validate_set.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para observar los datos de entrenamiento y validación.\n",
    "train_set[\"Close\"].plot(legend=True)\n",
    "validate_set[\"Close\"].plot(legend=True)\n",
    "plt.legend(['Train (2015 - 2022/09)', 'Validate (2022/10)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos de entrenamiento entre 0-1\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_set_normal = sc.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(0, 60, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\agusm\\OneDrive\\Escritorio\\LilMarcian-GitHub\\LilMarcian\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(0, 60, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[581], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_set)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(time_step, m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Datos: 0-time_step; 1-time_step+1; 2-time_step+2; etc.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     x_train\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(train_set[i, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_train), np\u001b[38;5;241m.\u001b[39marray(y_train)\n",
      "File \u001b[1;32mc:\\Users\\agusm\\OneDrive\\Escritorio\\LilMarcian-GitHub\\LilMarcian\\env\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\agusm\\OneDrive\\Escritorio\\LilMarcian-GitHub\\LilMarcian\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3803\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\agusm\\OneDrive\\Escritorio\\LilMarcian-GitHub\\LilMarcian\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(0, 60, None), 0)"
     ]
    }
   ],
   "source": [
    "# La red LSTM tendrá como entrada \"time_step\" datos consecutivos, y como salida 1 dato (es el resultado de la predicción a partir de esos \"time_step\" datos). Se conforma de esta manera el set de entrenamiento.\n",
    "time_step = 60\n",
    "x_train = []\n",
    "y_train = []\n",
    "m = len(train_set)\n",
    "\n",
    "for i in range(time_step, m):\n",
    "    # Datos: 0-time_step; 1-time_step+1; 2-time_step+2; etc.\n",
    "    x_train.append(train_set[i-time_step:i, 0])\n",
    "\n",
    "    y_train.append(train_set[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino el modelo de entrada y salida de la red\n",
    "dim_entry = (x_train.shape[1], 1)\n",
    "dim_out = 1\n",
    "na = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino la red secuencial\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=na, input_shape=dim_entry, activation=\"relu\"))\n",
    "model.add(Dense(units=dim_out))\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparo los datos de prueba\n",
    "x_test = validate_set.values\n",
    "x_test = sc.transform(x_test)\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(len(x_test) - time_step):\n",
    "    sequence = x_test[i:i + time_step, 0]\n",
    "    X_test.append(sequence)\n",
    "\n",
    "validate_set = validate_set.iloc[:-60]\n",
    "\n",
    "print(len(validate_set))\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo la predicción\n",
    "prediction = model.predict(X_test)\n",
    "prediction = sc.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_prediction(validate_set.reset_index(), prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mientras más cercano a 0 mejor\n",
    "mse = mean_squared_error(validate_set, prediction)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mientras más cercano a 1 mejor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(validate_set, prediction)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_real_data = np.var(validate_set)\n",
    "\n",
    "# Calcula el porcentaje de efectividad con MSE\n",
    "effectiveness_mse = 100 * (1 - mse / variance_real_data)\n",
    "\n",
    "# Calcula el porcentaje de efectividad con R^2\n",
    "effectiveness_r2 = r2 * 100\n",
    "\n",
    "print(f\"Porcentaje de efectividad (MSE): {effectiveness_mse[0]}%\")\n",
    "print(f\"Porcentaje de efectividad (R^2): {effectiveness_r2}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0472aa9c384a9239f6715ddb2f043cd9922a4970077915a84953f1d795e50591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
